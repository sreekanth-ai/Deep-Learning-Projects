{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8216664",
   "metadata": {},
   "source": [
    "## Train & Save CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa74b2f",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fae4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras import layers,models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cadeef",
   "metadata": {},
   "source": [
    "### 2. Load the CSV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2db722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fer2013.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5156c215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(48.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pix_shape = np.sqrt(len(data['pixels'][0].split()))\n",
    "pix_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ea00e",
   "metadata": {},
   "source": [
    "### 3. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b159dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist()\n",
    "X = np.array([np.fromstring(p,dtype='int',sep=' ') for p in pixels])\n",
    "X = X.reshape(-1,48,48,1)\n",
    "X = X / 255.0  # normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e2335be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Convert labels to one-hot\n",
    "y = to_categorical(data['emotion'], num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74adf53",
   "metadata": {},
   "source": [
    "### 4. Split into train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2615b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adcbe95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 48, 48, 1), (7178, 48, 48, 1), (28709, 7), (7178, 7))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4511a12",
   "metadata": {},
   "source": [
    "### 5. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55452394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(48,48,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(7,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688c2ec",
   "metadata": {},
   "source": [
    "### 6. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a9173d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422fac4",
   "metadata": {},
   "source": [
    "### 7. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe83dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 114ms/step - accuracy: 0.3547 - loss: 1.6318 - val_accuracy: 0.4436 - val_loss: 1.4623\n",
      "Epoch 2/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.4679 - loss: 1.3894 - val_accuracy: 0.4964 - val_loss: 1.3304\n",
      "Epoch 3/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.5159 - loss: 1.2761 - val_accuracy: 0.5219 - val_loss: 1.2579\n",
      "Epoch 4/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 110ms/step - accuracy: 0.5451 - loss: 1.1933 - val_accuracy: 0.5463 - val_loss: 1.2132\n",
      "Epoch 5/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 102ms/step - accuracy: 0.5689 - loss: 1.1316 - val_accuracy: 0.5506 - val_loss: 1.1871\n",
      "Epoch 6/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 109ms/step - accuracy: 0.5953 - loss: 1.0710 - val_accuracy: 0.5630 - val_loss: 1.1683\n",
      "Epoch 7/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 113ms/step - accuracy: 0.6190 - loss: 1.0160 - val_accuracy: 0.5575 - val_loss: 1.1819\n",
      "Epoch 8/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 106ms/step - accuracy: 0.6382 - loss: 0.9649 - val_accuracy: 0.5536 - val_loss: 1.2146\n",
      "Epoch 9/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6630 - loss: 0.9049 - val_accuracy: 0.5688 - val_loss: 1.1883\n",
      "Epoch 10/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 104ms/step - accuracy: 0.6847 - loss: 0.8556 - val_accuracy: 0.5652 - val_loss: 1.1946\n",
      "Epoch 11/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 107ms/step - accuracy: 0.7016 - loss: 0.8029 - val_accuracy: 0.5581 - val_loss: 1.2171\n",
      "Epoch 12/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 111ms/step - accuracy: 0.7290 - loss: 0.7411 - val_accuracy: 0.5709 - val_loss: 1.2837\n",
      "Epoch 13/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 112ms/step - accuracy: 0.7477 - loss: 0.6873 - val_accuracy: 0.5634 - val_loss: 1.3465\n",
      "Epoch 14/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.7671 - loss: 0.6336 - val_accuracy: 0.5634 - val_loss: 1.4243\n",
      "Epoch 15/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 118ms/step - accuracy: 0.7905 - loss: 0.5784 - val_accuracy: 0.5635 - val_loss: 1.4374\n",
      "Epoch 16/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 127ms/step - accuracy: 0.8094 - loss: 0.5234 - val_accuracy: 0.5482 - val_loss: 1.5233\n",
      "Epoch 17/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 128ms/step - accuracy: 0.8283 - loss: 0.4777 - val_accuracy: 0.5585 - val_loss: 1.6397\n",
      "Epoch 18/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 137ms/step - accuracy: 0.8432 - loss: 0.4342 - val_accuracy: 0.5536 - val_loss: 1.7524\n",
      "Epoch 19/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 138ms/step - accuracy: 0.8588 - loss: 0.3874 - val_accuracy: 0.5563 - val_loss: 1.8601\n",
      "Epoch 20/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 126ms/step - accuracy: 0.8751 - loss: 0.3453 - val_accuracy: 0.5532 - val_loss: 1.9489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19c2fde9400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f417a01",
   "metadata": {},
   "source": [
    "### 8. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8462774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as emotion_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"emotion_model.keras\")\n",
    "print(\"✅ Model saved as emotion_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e404c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
